{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "drugs = pd.read_csv('/Users/savrajsian/Library/CloudStorage/OneDrive-ImperialCollegeLondon/Documents/Drug_list_265.csv')\n",
    "#print(drugs)\n",
    "\n",
    "nontoxic_ids = '/Users/savrajsian/Library/CloudStorage/OneDrive-ImperialCollegeLondon/Documents/gdsc_drugMedianGE0.txt'\n",
    "nontoxic_ids = list(pd.read_csv(nontoxic_ids, header=None)[0].values.astype(int))\n",
    "\n",
    "nontoxic_drugs = drugs[drugs['drug_id'].isin(nontoxic_ids)]\n",
    "nontoxic_drugs.to_csv('/Users/savrajsian/Library/CloudStorage/OneDrive-ImperialCollegeLondon/Documents/nontoxic_drug_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 {'Olaparib', 'Afatinib', 'Tretinoin', 'Bexarotene', 'Methotrexate', 'Etoposide', 'Dabrafenib', 'Cytarabine', 'Ruxolitinib', 'Bosutinib', 'Ponatinib', 'Palbociclib', 'Pazopanib', 'Dasatinib', 'Bicalutamide', 'Imatinib', 'Erlotinib', 'Rucaparib', 'Gefitinib', 'Lenalidomide', 'Axitinib', 'Nilotinib', 'Vismodegib', 'Alectinib', 'Cisplatin', 'Cetuximab', 'Crizotinib', 'Pyrimethamine', 'Cabozantinib', 'Temozolomide', 'Lapatinib', 'Vorinostat', 'Trametinib', 'Talazoparib', 'Sorafenib', 'Sunitinib', 'Bleomycin', 'Idelalisib', 'Tamoxifen'}\n"
     ]
    }
   ],
   "source": [
    "#get drugs in ADRCS and nontoxic\n",
    "ADRCS_path = '/Users/savrajsian/Library/CloudStorage/OneDrive-ImperialCollegeLondon/Documents/FYP/drug side effect reaction stuff/ADRCS/'\n",
    "ADRCS_drugs = pd.read_csv(ADRCS_path + 'Drug_information.csv')\n",
    "\n",
    "#concat nontoxic_drugs name and synonyms\n",
    "nontoxic_all_names = nontoxic_drugs.copy()\n",
    "nontoxic_all_names = nontoxic_all_names.drop(columns=['Targets', 'Target pathway', 'Sample Size', 'Count'])\n",
    "nontoxic_all_names['Name'] = nontoxic_all_names['Name'].fillna('')\n",
    "nontoxic_all_names['Synonyms'] = nontoxic_all_names['Synonyms'].fillna('')\n",
    "nontoxic_all_names.loc[:, 'combined'] = nontoxic_all_names['Name'].str.cat(nontoxic_all_names['Synonyms'], sep=', ')\n",
    "\n",
    "#concat ADRCS_drugs name and synonyms\n",
    "ADRCS_all_names = ADRCS_drugs.copy()\n",
    "ADRCS_all_names['DRUG_NAME'] = ADRCS_all_names['DRUG_NAME'].fillna('')\n",
    "ADRCS_all_names['DRUG_SYNONYMS'] = ADRCS_all_names['DRUG_SYNONYMS'].fillna('')\n",
    "ADRCS_all_names.loc[:, 'combined'] = ADRCS_all_names['DRUG_NAME'].str.cat(ADRCS_all_names['DRUG_SYNONYMS'], sep=', ')\n",
    "\n",
    "#see what drugs are in both\n",
    "\n",
    "names1 = set(nontoxic_all_names['combined'].str.split(',').sum())\n",
    "names2 = set(ADRCS_all_names['combined'].str.split(',').sum())\n",
    "\n",
    "common_names = names1.intersection(names2)\n",
    "print(len(common_names), common_names)\n",
    "\n",
    "ADRCS_common = ADRCS_all_names[ADRCS_all_names['combined'].str.split(',').apply(lambda x: any([i in common_names for i in x]))]\n",
    "\n",
    "\n",
    "drugs_in_common = nontoxic_all_names[nontoxic_all_names['combined'].str.split(',').apply(lambda x: any([i in common_names for i in x]))]\n",
    "drugs_in_common = drugs_in_common.drop_duplicates(subset='combined')\n",
    "#append DRUG_ID from ADRCS_common to drugs_in_common\n",
    "name_to_id = ADRCS_all_names.set_index('DRUG_NAME')['DRUG_ID'].to_dict()\n",
    "drugs_in_common['BADD_ID'] = drugs_in_common['Name'].map(name_to_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load drug-adr interaction data\n",
    "#all_interactions = pd.read_csv('Drug_ADR_interactions.txt', sep='\\t')\n",
    "#interactions_in_common = all_interactions[all_interactions['DRUG_ID'].isin(drugs_in_common['BADD_ID'])]\n",
    "#quantitative version - more useful\n",
    "\n",
    "\n",
    "all_interactions_quantitative = pd.read_csv('Drug_ADR_relations_quantification.txt', sep='\\t')\n",
    "interactions_in_common_quantitative = all_interactions_quantitative[all_interactions_quantitative['DRUG_ID'].isin(drugs_in_common['BADD_ID'])]\n",
    "#get number of interactions for each drug\n",
    "drug_id_counts = interactions_in_common_quantitative['DRUG_ID'].value_counts()\n",
    "#print('interactions per drug:', drug_id_counts)\n",
    "#count number of ADR terms\n",
    "adr_counts = interactions_in_common_quantitative['ADR_TERM'].value_counts()\n",
    "#print('times each ADR term appears:', adr_counts)\n",
    "#unique ADR terms\n",
    "unique_adrs = interactions_in_common_quantitative['ADR_TERM'].unique()\n",
    "#print('unique ADR terms:', len(unique_adrs))\n",
    "\n",
    "#count severity of ADRs\n",
    "severity_counts = interactions_in_common_quantitative['ADR_Severity_Grade_FAERS'].value_counts()\n",
    "#print(severity_counts)\n",
    "\n",
    "#get number of severity grades for each drug\n",
    "drug_severity_counts = interactions_in_common_quantitative.pivot_table(index='DRUG_ID', columns='ADR_Severity_Grade_FAERS', aggfunc='size', fill_value=0)\n",
    "#print(drug_severity_counts)\n",
    "\n",
    "#append onto drugs_in_common\n",
    "drugs_with_severities = drugs_in_common.copy()\n",
    "drugs_with_severities = drugs_in_common.merge(drug_severity_counts, left_on='BADD_ID', right_index=True, how='left')\n",
    "drugs_with_severities = drugs_with_severities.dropna(axis = 0, how='any', subset=['Mild', 'Moderate', 'Severe', 'Lifethreatening', 'Death'])\n",
    "\n",
    "#save to csv\n",
    "drugs_with_severities.to_csv('drugs_with_severities.csv', index=False)\n",
    "\n",
    "#save drug ids as txt\n",
    "#use this file in the prepare.py file - replace gdsc_drugMedianGE0.txt with this file so only these are included\n",
    "drug_ids = drugs_with_severities['drug_id'].values\n",
    "np.savetxt('drugs_with_severities_ids.txt', drug_ids, fmt='%d') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring system for severities\n",
    "# point system for each severity grade\n",
    "# then sum for each drug\n",
    "# normalise by number of interactions\n",
    "\n",
    "severity_scores = drugs_with_severities[['Mild', 'Moderate', 'Severe', 'Lifethreatening', 'Death']].copy()\n",
    "severity_scores = severity_scores.replace('None', 0)\n",
    "severity_scores = severity_scores.astype(int)\n",
    "severity_scores = severity_scores * np.array([1, 2, 3, 5, 7]) #points for each severity grade\n",
    "severity_scores['total'] = severity_scores.sum(axis=1)\n",
    "# normalise by number of interactions\n",
    "interactions_per_drug = drugs_with_severities[['Mild', 'Moderate', 'Severe', 'Lifethreatening', 'Death']].sum(axis=1)\n",
    "severity_scores['normalised'] = severity_scores['total'] / interactions_per_drug\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
